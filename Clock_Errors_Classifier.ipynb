{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Clock_Errors_Classifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNuLHotDMWf5oey54QIFXuQ"},"kernelspec":{"name":"python3","display_name":"Python 3.7.8 64-bit","metadata":{"interpreter":{"hash":"57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YgD_5lGXKSmG","executionInfo":{"status":"ok","timestamp":1613444876782,"user_tz":-330,"elapsed":6245,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"3e3443ff-7391-4ba4-b2f7-e053b9f85885"},"source":["!pip install efficientnet\r\n","import efficientnet.tfkeras as efn"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["'pip' is not recognized as an internal or external command,\noperable program or batch file.\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'efficientnet'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m<ipython-input-2-27138286480b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install efficientnet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mefficientnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfkeras\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mefn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'efficientnet'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"io7J51nIkkNX","executionInfo":{"status":"ok","timestamp":1613444876784,"user_tz":-330,"elapsed":5595,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"2966f883-e806-448c-c3f8-49b1162b433e"},"source":["from sklearn.metrics import classification_report, accuracy_score\r\n","import matplotlib.pyplot as plt\r\n","from os.path import join\r\n","import tensorflow as tf\r\n","import pandas as pd\r\n","import numpy as np\r\n","import os\r\n","import re\r\n","\r\n","print(\"Tensorflow version \" + tf.__version__)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Tensorflow version 2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1q7SSjrttNEC","executionInfo":{"status":"ok","timestamp":1613444876785,"user_tz":-330,"elapsed":3596,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}}},"source":["from keras import backend as K"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJuPBMbYsJR4","executionInfo":{"status":"ok","timestamp":1613444900273,"user_tz":-330,"elapsed":24605,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"192ca4d9-6c10-463f-f0ef-fb020facc8a9"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpRzRd9bksuW","executionInfo":{"status":"ok","timestamp":1613444900277,"user_tz":-330,"elapsed":4960,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"0cb09a3f-0b27-4ca9-864b-4072bbfcc7bb"},"source":["# Detect hardware, return appropriate distribution strategy\r\n","try:\r\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\r\n","    print('Running on TPU ', tpu.master())\r\n","except ValueError:\r\n","    tpu = None\r\n","\r\n","if tpu:\r\n","    tf.config.experimental_connect_to_cluster(tpu)\r\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n","else:\r\n","    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\r\n","\r\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["REPLICAS:  1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EDpiyrPLsV17"},"source":["# Set the data path"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"W3ScIltLseRv","executionInfo":{"status":"ok","timestamp":1613444900280,"user_tz":-330,"elapsed":2631,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"ea6e0b26-724f-4c8a-a7cd-225b2eb88a8e"},"source":["files_path = 'drive/MyDrive/Colab Notebooks/sheethal sheethal/final_deliverable'\r\n","files_path"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'drive/MyDrive/Colab Notebooks/sheethal sheethal/final_deliverable'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hRTbgXe-9ed8","executionInfo":{"status":"ok","timestamp":1613444968034,"user_tz":-330,"elapsed":963,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"21659187-c1fc-4312-eaa7-574151122d2b"},"source":["!ls -al 'drive/MyDrive/Colab Notebooks/sheethal sheethal/final_deliverable/models/'"],"execution_count":14,"outputs":[{"output_type":"stream","text":["total 3318086\n","-rw------- 1 root root  813740488 Feb 15 06:58 effnetB7_correct_plus_incorrect.h5\n","-rw------- 1 root root 2583978712 Feb 14 15:45 EffNetB7_correct_plus_incorrect.h5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KLmvaiwpk8JG"},"source":["# Set Parameters"]},{"cell_type":"code","metadata":{"id":"54Sl6WtWijn-"},"source":["def count_images(dir):\r\n","  files = tf.io.gfile.glob(dir + '/*.tfrec')\r\n","  return sum([int(re.search(r'-([0-9]*)\\.', file).group(1)) for file in files])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUO56xcvkvlF"},"source":["IMAGE_SIZE = [224, 224] # at this size, a GPU will run out of memory. Use the TPU\r\n","\r\n","# number of time the model will be fitted\r\n","EPOCHS = 5\r\n","\r\n","# number of images trained at a time\r\n","BATCH_SIZE = 8 * strategy.num_replicas_in_sync\r\n","\r\n","# get the count of train, val and test images\r\n","NUM_TRAINING_IMAGES = count_images(files_path + '/data/train_tfrecs')\r\n","NUM_VALIDATION_IMAGES = count_images(files_path + '/data/val_tfrecs')\r\n","NUM_TEST_IMAGES = count_images(files_path + '/data/test_tfrecs')\r\n","\r\n","# number of batch of images to be trained per epoch\r\n","TRAIN_STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE + 1\r\n","VAL_STEPS_PER_EPOCH = NUM_VALIDATION_IMAGES // BATCH_SIZE + 1\r\n","\r\n","# number of classes in the dataset\r\n","NUM_CLASSES = 3\r\n","\r\n","# class mapping\r\n","CLASS_MAPPING = {0: 'Correct', '1': 'Hand Error', 2: 'Numbering Error'}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VWa3XBcX3fqL"},"source":["### Distribution of Classes in Training data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6qbUQWTG3bYI","executionInfo":{"status":"ok","timestamp":1613378997543,"user_tz":-330,"elapsed":11105,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"8a0cd886-5710-4bd6-934d-b995b381d01c"},"source":["train_data = pd.read_csv(files_path + '/data/train_label.csv')\r\n","train_data['error_type'].value_counts(normalize=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["correct      0.33724\n","numbering    0.33364\n","hand         0.32912\n","Name: error_type, dtype: float64"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"6vLFmQc637wZ"},"source":["### Distribution of Classes in Validation data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MhETeVs3364U","executionInfo":{"status":"ok","timestamp":1613378997544,"user_tz":-330,"elapsed":11092,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"0c238076-2bbe-4d33-8081-a8d0c020778e"},"source":["val_data = pd.read_csv(files_path + '/data/val_label.csv')\r\n","val_data['error_type'].value_counts(normalize=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["correct      0.3348\n","hand         0.3344\n","numbering    0.3308\n","Name: error_type, dtype: float64"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"oK4pSgjAlM75"},"source":["# Load the data"]},{"cell_type":"code","metadata":{"id":"ySG8_hNXk6VL"},"source":["def decode_image(image_data):\r\n","    image = tf.image.decode_jpeg(image_data, channels=3)\r\n","    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\r\n","    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\r\n","    return image\r\n","\r\n","def read_labeled_tfrecord(example):\r\n","    LABELED_TFREC_FORMAT = {\r\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\r\n","        \"image_name\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\r\n","        'hour': tf.io.FixedLenFeature([], tf.int64),\r\n","        'minute': tf.io.FixedLenFeature([], tf.int64),\r\n","        'error_type': tf.io.FixedLenFeature([], tf.string)\r\n","    }\r\n","    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\r\n","    image = decode_image(example['image'])\r\n","\r\n","    labels = [0, 0, 0]\r\n","\r\n","    if example['error_type'] == 'correct':\r\n","      labels[0] = 1\r\n","    elif example['error_type'] == 'hand':\r\n","      labels[1] = 1\r\n","    elif example['error_type'] == 'numbering':\r\n","      labels[2] = 1\r\n","\r\n","    # label = 0\r\n","    # if example['error_type'] == 'correct':\r\n","    #   label = 1\r\n","    # elif example['error_type'] == 'hand':\r\n","    #   label = 2\r\n","    # elif example['error_type'] == 'numbering':\r\n","    #   label = 3\r\n","    \r\n","    # label = 1 if example['error_type'] == 'correct' else 0\r\n","    return image, labels # returns a dataset of (image, label) pairs\r\n","\r\n","def read_unlabeled_tfrecord(example):\r\n","    UNLABELED_TFREC_FORMAT = {\r\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\r\n","        \"image_name\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\r\n","        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\r\n","    }\r\n","    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\r\n","    image = decode_image(example['image'])\r\n","    idnum = example['image_name']\r\n","    return image, idnum # returns a dataset of image(s)\r\n","\r\n","def load_dataset(filenames, labeled=True, ordered=False):\r\n","    # Read from TFRecords. For optimal performance, reading from multiple files at once and\r\n","    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\r\n","\r\n","    ignore_order = tf.data.Options()\r\n","    if not ordered:\r\n","        ignore_order.experimental_deterministic = False # disable order, increase speed\r\n","\r\n","    dataset = tf.data.TFRecordDataset(filenames) # automatically interleaves reads from multiple files\r\n","    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\r\n","    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\r\n","    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\r\n","    return dataset\r\n","\r\n","def get_training_dataset():\r\n","    dataset = load_dataset(tf.io.gfile.glob(files_path + '/data/train_tfrecs/*.tfrec'), labeled=True)\r\n","    dataset = dataset.repeat(EPOCHS) # the training dataset must repeat for several epochs\r\n","    dataset = dataset.shuffle(2048)\r\n","    dataset = dataset.batch(BATCH_SIZE)\r\n","    return dataset\r\n","\r\n","def get_validation_dataset():\r\n","    dataset = load_dataset(tf.io.gfile.glob(files_path + '/data/val_tfrecs/*.tfrec'), labeled=True, ordered=True)\r\n","    dataset = dataset.repeat(EPOCHS) # the training dataset must repeat for several epochs\r\n","    dataset = dataset.batch(BATCH_SIZE)\r\n","    # dataset = dataset.cache()\r\n","    return dataset\r\n","\r\n","def get_test_dataset(ordered=False, labeled=False):\r\n","    dataset = load_dataset(tf.io.gfile.glob(files_path + '/data/test_tfrecs/*.tfrec'), labeled=labeled, ordered=ordered)\r\n","    dataset = dataset.batch(BATCH_SIZE)\r\n","    return dataset\r\n","\r\n","training_dataset = get_training_dataset()\r\n","validation_dataset = get_validation_dataset()\r\n","# test_dataset = get_test_dataset()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KU3V_AEMlu-l"},"source":[]},{"cell_type":"markdown","metadata":{"id":"3oG1bzxqvdwz"},"source":["# Build the Model - with 3 Classes (Correct, Hand Error & Numbering Error)"]},{"cell_type":"code","metadata":{"id":"bToD_n7qLCrm"},"source":["with strategy.scope():\n","    effnetB7_pretrained_model =  efn.EfficientNetB7(weights='imagilenet', include_top=False, pooling='avg', input_shape=[*IMAGE_SIZE, 3])\n","    effnetB7_pretrained_model.trainable = True # False = transfer learning, True = fine-tuning\n","    \n","    effnetB7 = tf.keras.Sequential([\n","        effnetB7_pretrained_model,\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(1024, activation='relu'),\n","        tf.keras.layers.Dense(1024, activation='relu'),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n","    ])\n","        \n","effnetB7.compile(\n","    optimizer='adam',\n","    loss = 'categorical_crossentropy',\n","    metrics=['accuracy']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xD4XECW_F7Rt"},"source":["set the learning rate for the model\n","K.set_value(effnetB7.optimizer.learning_rate, 0.001)\n","\n","fit the model\n","historical = effnetB7.fit(\n","              training_dataset, \n","              steps_per_epoch=TRAIN_STEPS_PER_EPOCH, \n","              epochs=5, \n","              validation_data=validation_dataset,\n","              validation_steps=VAL_STEPS_PER_EPOCH\n","            )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MI3qQkRjlV-l"},"source":["## Store the model"]},{"cell_type":"code","metadata":{"id":"6wkYIgVaDWW1"},"source":["# effnetB7.save(join(files_path, 'models/effnetB7_correct_plus_incorrect.h5')) #.replace(' ', '\\ ')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vc4UAiCCDYTx"},"source":["# Load the model"]},{"cell_type":"code","metadata":{"id":"Vv6Wdfz-DW-D"},"source":["# load the saved model\r\n","model = tf.keras.models.load_model(join(files_path, 'models/effnetB7_correct_plus_incorrect.h5'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rppH2IHGlRGn"},"source":["### Accuracy on the valiadtion dataset"]},{"cell_type":"code","metadata":{"id":"ZE93S67xJL5a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613378691815,"user_tz":-330,"elapsed":745792,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"e2f0fbf8-9a25-4c9e-a84a-036d1bcb0365"},"source":["# accuracy on the validation dataset\r\n","model.evaluate(validation_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6250/6250 [==============================] - 684s 108ms/step - loss: 0.1910 - accuracy: 0.9338\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.19096213579177856, 0.9337999820709229]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"FWL47vowu1nr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613379267166,"user_tz":-330,"elapsed":191195,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"82c960d6-ee2b-4c51-c8b7-571fcd4b895c"},"source":["# classification report\r\n","x_val = next(iter(validation_dataset.map(lambda img, label: img).unbatch().batch(NUM_VALIDATION_IMAGES)))\r\n","y_val = next(iter(validation_dataset.map(lambda img, label: label).unbatch().batch(NUM_VALIDATION_IMAGES))).numpy().argmax(axis=1)\r\n","\r\n","y_val_pred = model.predict(x_val).argmax(axis=1)\r\n","\r\n","print(classification_report(y_val, y_val_pred, target_names=list(CLASS_MAPPING.values())))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                 precision    recall  f1-score   support\n","\n","        Correct       0.84      1.00      0.91      3348\n","     Hand Error       1.00      0.99      1.00      3344\n","Numbering Error       1.00      0.81      0.89      3308\n","\n","       accuracy                           0.93     10000\n","      macro avg       0.94      0.93      0.93     10000\n","   weighted avg       0.94      0.93      0.93     10000\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1NpgUa5Ylkq7"},"source":["## Display Training curves"]},{"cell_type":"code","metadata":{"id":"9cnaeLvRlyRE"},"source":["def display_training_curves(training, validation, title, subplot):\r\n","    if subplot%10==1: # set up the subplots on the first call\r\n","        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\r\n","        plt.tight_layout()\r\n","    ax = plt.subplot(subplot)\r\n","    ax.set_facecolor('#F8F8F8')\r\n","    ax.plot(training)\r\n","    ax.plot(validation)\r\n","    ax.set_title('model '+ title)\r\n","    ax.set_ylabel(title)\r\n","    #ax.set_ylim(0.28,1.05)\r\n","    ax.set_xlabel('epoch')\r\n","    ax.legend(['train', 'valid'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8TPx9vGmljZU"},"source":["display_training_curves(historical.history['loss'], historical.history['val_loss'], 'loss', 211)\r\n","display_training_curves(historical.history['accuracy'], historical.history['val_accuracy'], 'accuracy', 212)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dr7YTiu3xSeR"},"source":["# Make Predictions"]},{"cell_type":"code","metadata":{"id":"dtW7rNagxXNS","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1613379827695,"user_tz":-330,"elapsed":138975,"user":{"displayName":"Prateek Jain","photoUrl":"","userId":"15429652888968192215"}},"outputId":"10bf8626-b0a9-48f8-f6c3-dbc8b9ff003b"},"source":["# load test data\r\n","test_dataset = get_test_dataset(labeled=False, ordered=True)\r\n","\r\n","# extract the images\r\n","x_test = test_dataset.map(lambda img, imgid: img)\r\n","\r\n","# extract the image ids\r\n","img_ids_test = next(iter(test_dataset.map(lambda img, imgid: imgid).unbatch().batch(NUM_TEST_IMAGES))).numpy()\r\n","\r\n","# make predictions\r\n","y_test_pred = model.predict(x_test).argmax(axis=1)\r\n","\r\n","# create data frame\r\n","submission = pd.DataFrame()\r\n","submission['image_id'] = img_ids_test\r\n","submission['label'] = y_test_pred\r\n","submission.head(100)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_id</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b'0.jpg'</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>b'1.jpg'</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b'2.jpg'</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>b'3.jpg'</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b'4.jpg'</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>b'95.jpg'</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>b'96.jpg'</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>b'97.jpg'</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>b'98.jpg'</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>b'99.jpg'</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 2 columns</p>\n","</div>"],"text/plain":["     image_id  label\n","0    b'0.jpg'      2\n","1    b'1.jpg'      2\n","2    b'2.jpg'      2\n","3    b'3.jpg'      2\n","4    b'4.jpg'      0\n","..        ...    ...\n","95  b'95.jpg'      2\n","96  b'96.jpg'      2\n","97  b'97.jpg'      0\n","98  b'98.jpg'      2\n","99  b'99.jpg'      1\n","\n","[100 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":26}]}]}